{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/lift-drop-right_arm/data\n",
      "/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/lift-drop-left_arm/data\n",
      "/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/push-pull-left_arm/data\n",
      "/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/push-pull-right_arm/data\n",
      "\n",
      "/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/lift-drop-right_arm/labels\n",
      "/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/lift-drop-left_arm/labels\n",
      "/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/push-pull-left_arm/labels\n",
      "/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/push-pull-right_arm/labels\n"
     ]
    }
   ],
   "source": [
    "jointMu = 0\n",
    "jointSig = 0.001\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import readline\n",
    "import GPy\n",
    "from SAM.SAM_Core import SAMCore\n",
    "from SAM.SAM_Core import SAMDriver\n",
    "import pylab as pb\n",
    "import sys \n",
    "from sys import executable\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, walk, system\n",
    "from os.path import isfile, join, isdir\n",
    "import time\n",
    "import operator\n",
    "import numpy\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import datetime\n",
    "import yarp\n",
    "import copy\n",
    "from itertools import combinations \n",
    "from ConfigParser import SafeConfigParser\n",
    "from scipy.spatial import distance\n",
    "from numpy.linalg import inv\n",
    "import math\n",
    "import ipyparallel as ipp\n",
    "import random\n",
    "from SAM.SAM_Core import staticPose\n",
    "\n",
    "dataSetFolder = '/home/daniel/WYSIWYD_PROJECT/actionRecognitionDatasetOld/'\n",
    "dataFolderList = ['lift-drop-right_arm', \n",
    "                  'lift-drop-left_arm', \n",
    "                  'push-pull-left_arm', \n",
    "                  'push-pull-right_arm']\n",
    "\n",
    "dataFolders = []\n",
    "labelFolders = []\n",
    "#check folders in list actually exist\n",
    "for j in dataFolderList:\n",
    "    t = join(dataSetFolder,j,'data')\n",
    "    m = join(dataSetFolder,j,'labels')\n",
    "    if(isdir(t) and isdir(m)):\n",
    "        dataFolders.append(t)\n",
    "        labelFolders.append(m)\n",
    "print '\\n'.join(dataFolders)\n",
    "print\n",
    "print '\\n'.join(labelFolders)\n",
    "#subDirFolderList = ['camera/left', 'camera/right', 'data', 'kinect/rgb', 'labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distEuc(a,b):\n",
    "    temp = a-b\n",
    "    temp = np.square(temp)\n",
    "    temp = np.sum(temp,1)\n",
    "    return np.sqrt(temp)\n",
    "\n",
    "def qtc_2D(k,l,q,thresh):\n",
    "    \n",
    "    d1 = distEuc(k[:-2],l[1:-1])\n",
    "    d2 = distEuc(k[1:-1],l[1:-1])\n",
    "    d3 = distEuc(k[2:],l[1:-1])\n",
    "    \n",
    "    for i in range(len(d1)):\n",
    "        #threshold distance moved\n",
    "        diff1 = d2[i]-d1[i]\n",
    "        if(np.abs(diff1) < thresh):\n",
    "            diff1 = 0\n",
    "\n",
    "        diff2 = d3[i]-d2[i]\n",
    "        if(np.abs(diff2) < thresh):\n",
    "            diff2 = 0\n",
    "\n",
    "        #convert to qtc\n",
    "        if(diff1 > 0 and diff2 > 0):\n",
    "            q[i] = -1\n",
    "        elif(diff1 < 0 and diff2 < 0):\n",
    "            q[i] = +1\n",
    "        else:\n",
    "            q[i] = 0\n",
    "    \n",
    "    return d2\n",
    "\n",
    "def frenetFrame(arr):\n",
    "    t_num = np.diff(arr,axis=0)\n",
    "    t = (t_num/np.abs(t_num)).astype(int)\n",
    "\n",
    "    b_num = np.cross(t[:-1],t[1:])\n",
    "    b = b_num/np.abs(b_num)\n",
    "    t = t[1:]\n",
    "\n",
    "    n = np.cross(b,t)\n",
    "\n",
    "    frameArr = np.concatenate((t,n,b),axis=1).T\n",
    "    fArr = frameArr.reshape((3,3,-1),order = 'F')\n",
    "    return fArr\n",
    "\n",
    "def qtc_3D(k, l, thresh, q3, q4, q5):\n",
    "    fFrameK = frenetFrame(k)\n",
    "    fFrameL = frenetFrame(l)\n",
    "    alpArr = np.zeros(q3.shape)\n",
    "    betArr = np.zeros(q3.shape)\n",
    "    gamArr = np.zeros(q3.shape)\n",
    "    \n",
    "    for g in range(fFrameK.shape[2]):\n",
    "        fKinv = np.linalg.pinv(fFrameK[:,:,g])\n",
    "        R = np.dot(fFrameL[:,:,g],fKinv)\n",
    "        \n",
    "        alpha = np.arctan(R[1,0]/R[0,0])\n",
    "        den = np.sqrt(pow(R[2,1],2) + pow(R[2,2],2))\n",
    "        \n",
    "        beta = np.arctan(-R[2,0]/den)\n",
    "        gamma = np.arctan(R[2,1]/R[2,2])\n",
    "\n",
    "        #threshold angles\n",
    "        if(np.abs(alpha) < thresh or math.isnan(alpha)):\n",
    "            alpha = 0\n",
    "        if(np.abs(beta) < thresh or math.isnan(beta)):\n",
    "            beta = 0\n",
    "        if(np.abs(gamma) < thresh or math.isnan(gamma)):\n",
    "            gamma = 0\n",
    "        alpArr[g] = alpha\n",
    "        betArr[g] = beta\n",
    "        gamArr[g] = gamma\n",
    "        \n",
    "        q3[g] = np.sign(alpha)\n",
    "        q4[g] = np.sign(beta)\n",
    "        q5[g] = np.sign(gamma)\n",
    "    \n",
    "    return [alpArr,betArr,gamArr]\n",
    "            \n",
    "def checkQTC(qtcArr):\n",
    "    #array of shape x by 11 with 0 to 4 of 11 being the ones that unique must apply to\n",
    "    tArr = copy.deepcopy(qtcArr)\n",
    "    for i in range(1,tArr.shape[0]):\n",
    "        if(i != 0):\n",
    "            currRow = tArr[i,:]\n",
    "            Mod = False\n",
    "            for q in range(tArr.shape[1]):\n",
    "                r = tArr[i,q] - tArr[i-1,q]\n",
    "                if(r == -2 or r == 2):\n",
    "                    Mod = True\n",
    "                    currRow[q] = 0\n",
    "            if(Mod):    \n",
    "                qtcArr = np.insert(qtcArr,i,currRow,axis=0)    \n",
    "                Mod = False\n",
    "    return qtcArr\n",
    "\n",
    "def uniqueQTC(currQTC):\n",
    "    #array of shape x by 11 with 0 to 4 of 11 being the ones that unique must apply to\n",
    "    i = 0\n",
    "    del1 = False\n",
    "    del2 = False\n",
    "    \n",
    "    while(i < currQTC.shape[0]-2):\n",
    "        if(i!=0):\n",
    "            if(np.array_equal(currQTC[i,:5],currQTC[i-1,:5])):\n",
    "                del1 = True\n",
    "            if(np.array_equal(currQTC[i+1,:5],currQTC[i-1,:5])):\n",
    "                del2 = True\n",
    "        \n",
    "        if(del1 and not del2):\n",
    "            currQTC = np.delete(currQTC,i,0)\n",
    "        elif(del2):\n",
    "            currQTC = np.delete(currQTC,i,0)\n",
    "            currQTC = np.delete(currQTC,i+1,0)\n",
    "            \n",
    "        i+=1\n",
    "    return currQTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:59: FutureWarning:comparison to `None` will result in an elementwise object comparison in the future.\n",
      " /home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:71: FutureWarning:comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-370f8d744e5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/daniel/anaconda2/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load kinect skeleton data for all folders in dataFolderList\n",
    "numJoints = 9\n",
    "data = dict()\n",
    "firstPass = True\n",
    "jointsList = []\n",
    "objectsList = []\n",
    "labelsList = []\n",
    "numFolders = len(dataFolders)\n",
    "\n",
    "for j in dataFolders:\n",
    "    k = dataFolders.index(j)\n",
    "    dataFile = open(join(dataFolders[k],'data.log'),'r')\n",
    "    labelFile = open(join(labelFolders[k],'data.log'),'r')\n",
    "    \n",
    "    #number of lines in dataFile\n",
    "    for i, l in enumerate(dataFile):\n",
    "            pass\n",
    "    lenDataFile = i+1\n",
    "    \n",
    "    #number of lines in labelFile\n",
    "    for i, l in enumerate(labelFile):\n",
    "            pass\n",
    "    lenLabelFile = i+1\n",
    "    dataFile.close()\n",
    "    labelFile.close()\n",
    "    \n",
    "    \n",
    "    if(lenLabelFile != lenDataFile):\n",
    "        raise ValueError('Files not of same lenght')\n",
    "    else:\n",
    "        dataFile = open(join(dataFolders[k],'data.log'),'r')\n",
    "        labelFile = open(join(labelFolders[k],'data.log'),'r')\n",
    "        labelsList.append([])\n",
    "        \n",
    "        for curr in range(lenDataFile):\n",
    "            line = dataFile.readline()\n",
    "            labelLine = labelFile.readline()\n",
    "            \n",
    "            t = line.replace('(','').replace(')','').split(' ')\n",
    "            del t[0:4]\n",
    "           \n",
    "            v = labelLine.split(' ')[2].replace('\\n','').replace('(','').replace(')','')\n",
    "            if(v == ''):\n",
    "                v = 'unknown'\n",
    "            labelsList[k].append(v)\n",
    "            \n",
    "            #parse skeleton data which has 9 sections by (x,y,z)\n",
    "            for i in range(numJoints):\n",
    "                a = i*4\n",
    "                if(t[a] == 'shoulderCenter'):\n",
    "                    t[a] = 'chest'\n",
    "                \n",
    "                if(firstPass):\n",
    "                    data[t[a]] = [None]*numFolders\n",
    "                    data[t[a]][k] = (np.array([float(t[a+1]), float(t[a+2]), float(t[a+3])]))\n",
    "                    jointsList.append(t[a])\n",
    "                else:\n",
    "                    arr =  np.array([float(t[a+1]), float(t[a+2]), float(t[a+3])])\n",
    "                    if(data[t[a]][k] != None):\n",
    "                        data[t[a]][k] = np.vstack((data[t[a]][k],arr))\n",
    "                    else:\n",
    "                        data[t[a]][k] = arr\n",
    "\n",
    "            currIdx = (numJoints*4 -1)\n",
    "            numObjs = (len(t) - currIdx)/5\n",
    "\n",
    "            for i in range(numObjs):\n",
    "                a = currIdx + 1 + (i*5)\n",
    "                if(t[a] in data):\n",
    "                    arr = np.array([float(t[a+1]), float(t[a+2]), float(t[a+3])])\n",
    "                    if(data[t[a]][k] != None):\n",
    "                        data[t[a]][k] =  np.vstack((data[t[a]][k],arr))\n",
    "                    else:\n",
    "                        data[t[a]][k] = arr\n",
    "                else:\n",
    "                    data[t[a]] = [None]*(numFolders)\n",
    "                    data[t[a]][k] = np.array([float(t[a+1]), float(t[a+2]), float(t[a+3])])\n",
    "                    objectsList.append(t[a])\n",
    "\n",
    "            firstPass = False\n",
    "            \n",
    "        dataFile.close()\n",
    "        labelFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'data has length = ' + str(len(data)) + ' joints'\n",
    "strl =  'each joint has ' + str(len(data['head'])) + ' arrays of shape: '\n",
    "\n",
    "for i in data['head']:\n",
    "    strl += str(i.shape) + ', '\n",
    "print strl\n",
    "\n",
    "strl = 'labelsList has length = ' + str(len(labelsList)) + ' with sizes: '\n",
    "for i in labelsList:\n",
    "    strl += str(len(i)) + ', '\n",
    "print strl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#compile a list of all unique labels\n",
    "setList = []\n",
    "for x in labelsList:\n",
    "    setList.append(list(set(x)))\n",
    "flattenedList = [val for sublist in setList for val in sublist]\n",
    "labels = list(set(flattenedList))\n",
    "labels.sort()\n",
    "for k in range(0,len(labels)):\n",
    "    print str(k) + '  ' + labels[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataStruct = []\n",
    "verbose = True\n",
    "for joint in jointsList+objectsList:\n",
    "        for arr in range(len(data[joint])):\n",
    "            for label in labels:\n",
    "                if(verbose):\n",
    "                    print\n",
    "                    print 'current joint: ' + str(joint)\n",
    "                    print 'curent label: ' + str(label)\n",
    "                    print 'current dataset = ' + str(dataFolderList[arr])\n",
    "                    print\n",
    "                idxs = [i for i in range(len(labelsList[arr])) if labelsList[arr][i] == label]\n",
    "                actionBlocks = []\n",
    "                startIdx = 0\n",
    "                for idxIndex in range(len(idxs)):\n",
    "                    if(idxIndex != 0):\n",
    "                        if(idxs[idxIndex] - idxs[idxIndex-1] != 1):\n",
    "                            endIdx = idxIndex-1\n",
    "                            actionData = data[joint][arr][startIdx:endIdx+1]\n",
    "                            dataStruct.append([joint, label, arr, actionData.shape[0], actionData])\n",
    "                            if(verbose):\n",
    "                                print '[%s]' % ', '.join(map(str, dataStruct[-1][:-1]))\n",
    "                            startIdx = idxIndex-1\n",
    "                            #include end of previous acion as start of next action\n",
    "                            #this is boundary idxIndex is start of next action and idxIndex-1 is end of previous action\n",
    "                        if(idxIndex+2 > len(idxs)):\n",
    "                            endIdx = idxIndex\n",
    "                            actionData = data[joint][arr][startIdx:endIdx+1]\n",
    "                            dataStruct.append([joint, label, arr, actionData.shape[0], actionData])\n",
    "                            if(verbose):\n",
    "                                print '[%s]' % ', '.join(map(str, dataStruct[-1][:-1]))\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joint = 0\n",
    "action = 1\n",
    "dataset = 2\n",
    "start = 3\n",
    "end = 4\n",
    "for a in range(len(dataFolderList)):\n",
    "    print 'Dataset ' + str(a) + ' : ' + dataFolderList[a]\n",
    "    for b in range(len(labels)):\n",
    "        y = len([i[1] for i in dataStruct if i[joint] == 'head' and i[dataset] == a and i[action] == labels[b]])\n",
    "        print '\\t ' + str(labels[b]).ljust(15) + ' = ' + str(y).ljust(3) + ' repetitions'\n",
    "    print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jointsList.sort()\n",
    "modJointsListHand_R = [i for i in jointsList if i != 'elbowRight' and i != 'handRight']\n",
    "modJointsListHand_L = [i for i in jointsList if i != 'elbowLeft' and i != 'handLeft']\n",
    "\n",
    "modJointsListHand_R = []\n",
    "modJointsListHand_L = []\n",
    "combinationList = []\n",
    "\n",
    "if(len(modJointsListHand_R) > 0):\n",
    "    for i in range(len(modJointsListHand_R)):\n",
    "        combinationList.append(['handLeft', modJointsListHand_L[i]])\n",
    "        combinationList.append(['handRight', modJointsListHand_R[i]])\n",
    "    del combinationList[combinationList.index(['handLeft', 'handRight'])]\n",
    "\n",
    "for i in objectsList[1:]:\n",
    "    combinationList.append(['handLeft',i])\n",
    "    combinationList.append(['handRight',i])\n",
    "\n",
    "\n",
    "print 'Available joint pairs for hands:'\n",
    "print\n",
    "for i in combinationList:\n",
    "    print '\\t' + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "humanStaticLabels = []\n",
    "humanStaticLabels.append('left of')\n",
    "humanStaticLabels.append('right of')\n",
    "humanStaticLabels.append('on top of')\n",
    "humanStaticLabels.append('underneath')\n",
    "humanStaticLabels.append('in front of')\n",
    "humanStaticLabels.append('behind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2 joint pairs will be used shoulder-hand and hand-object left and right doesnt matter\n",
    "#both combine within a single model\n",
    "#step 1 will be training these models with static poses to do clustering with a full GP configuration\n",
    "joint = 0\n",
    "action = 1\n",
    "dataset = 2\n",
    "start = 3\n",
    "end = 4\n",
    "verbose = True\n",
    "\n",
    "contactThreshold = 0.1\n",
    "deltaDistanceThreshold = 0.000005\n",
    "originThreshold = 0.01\n",
    "angleThreshold = 0.001\n",
    "\n",
    "firstPass = True\n",
    "handDataStruct = []\n",
    "\n",
    "for currComb in combinationList:\n",
    "    print str(currComb[0]) +'-' +str(currComb[1])\n",
    "    infoK = [i for i in dataStruct if i[joint] == currComb[0]]\n",
    "    infoL = [i for i in dataStruct if i[joint] == currComb[1]]\n",
    "    \n",
    "    for i in range(len(infoK)):\n",
    "        Pk = infoK[i][4]\n",
    "        Pl = infoL[i][4]\n",
    "        \n",
    "        #add gaussian noise on output\n",
    "        Pk_Noise = np.random.normal(jointMu, jointSig, Pk.shape)\n",
    "        Pl_Noise = np.random.normal(jointMu, jointSig, Pl.shape)\n",
    "        \n",
    "        Pk = Pk + Pk_Noise\n",
    "        Pl = Pl + Pl_Noise\n",
    "        \n",
    "        q1 = np.zeros((Pk.shape[0]-2,1), dtype=np.int) #motion of k relative to l\n",
    "        q2 = np.zeros((Pk.shape[0]-2,1), dtype=np.int) #motion of l relative to k\n",
    "        q3 = np.zeros((Pk.shape[0]-2,1), dtype=np.int) #alpha\n",
    "        q4 = np.zeros((Pk.shape[0]-2,1), dtype=np.int) #beta\n",
    "        q5 = np.zeros((Pk.shape[0]-2,1), dtype=np.int) #gamma\n",
    "        q7 = np.zeros((Pk.shape[0]-2,1), dtype=np.int) #contact\n",
    "        q8 = np.zeros((Pk.shape[0]-2,1), dtype=np.int) #human static label\n",
    "\n",
    "        lowV = np.abs(Pk) < originThreshold  # Where values are low\n",
    "        Pk[lowV] = 0\n",
    "        \n",
    "        lowV = np.abs(Pl) < originThreshold  # Where values are low\n",
    "        Pl[lowV] = 0\n",
    "        \n",
    "        q6 = (Pl[1:-1]-Pk[1:-1]) #direction vector from joint to joint\n",
    "\n",
    "        q9 = qtc_2D(Pk,Pl,q1, deltaDistanceThreshold)\n",
    "        lowV = np.abs(q9) < contactThreshold\n",
    "        q7[lowV] = 1\n",
    "        \n",
    "        q6 = q6/q9[:,None]\n",
    "        \n",
    "        qtc_2D(Pl,Pk,q2, deltaDistanceThreshold)\n",
    "        [a,b,g] = qtc_3D(Pk, Pl, angleThreshold, q3, q4, q5)\n",
    "        \n",
    "        for h in range(q6.shape[0]):\n",
    "            #x at 0 is depth with negative meaning behind an object\n",
    "            #y at 1 is width with negative meaning partner-right = ego-left\n",
    "            #x at 2 is height with negative meaning underneath\n",
    "            currVec = np.abs(q6[h,:])\n",
    "            maxIDx = currVec.argmax()\n",
    "            if(maxIDx == 0):\n",
    "                if(np.sign(q6[h,maxIDx]) == -1):\n",
    "                    #behind\n",
    "                    q8[h] = humanStaticLabels.index('behind')\n",
    "                elif(np.sign(q6[h,maxIDx]) == 1):\n",
    "                    #in front\n",
    "                    q8[h] = humanStaticLabels.index('in front of')\n",
    "            elif(maxIDx == 1):\n",
    "                if(np.sign(q6[h,maxIDx]) == -1):\n",
    "                    #left\n",
    "                    q8[h] = humanStaticLabels.index('left of')\n",
    "                elif(np.sign(q6[h,maxIDx]) == 1):\n",
    "                    #right\n",
    "                    q8[h] = humanStaticLabels.index('right of')\n",
    "            elif(maxIDx == 2):\n",
    "                if(np.sign(q6[h,maxIDx]) == -1):\n",
    "                    #underneath\n",
    "                    q8[h] = humanStaticLabels.index('underneath')\n",
    "                elif(np.sign(q6[h,maxIDx]) == 1):\n",
    "                    #top of\n",
    "                    q8[h] = humanStaticLabels.index('on top of')  \n",
    "        \n",
    "        q10 = Pl[1:-1]\n",
    "        q11 = Pk[1:-1]\n",
    "        tempQTC = np.hstack((q1,q2,q3,q4,q5,q6[:,0,None],q6[:,1,None],q6[:,2,None],q7,q8,q9[:,None],q10[:,0,None],q10[:,1,None],q10[:,2,None],q11[:,0,None],q11[:,1,None],q11[:,2,None]))\n",
    "        \n",
    "        #q1,q2 -> relative movement of points in terms of distance from each other (closer / farther)\n",
    "        #q3-5-> relative movement of joints in tems of orientation from each other (difference in the paths they are following wrt each other)\n",
    "        #q6_1 to _3 -> direction vector from hand to other joint\n",
    "        #q7 -> contact status\n",
    "        #q8 -> humanStaticLabel\n",
    "        \n",
    "        g = tempQTC.shape[0]\n",
    "        tempQTC2 = uniqueQTC(tempQTC)\n",
    "\n",
    "        gg = tempQTC2.shape[0]\n",
    "        \n",
    "        tempQTC = checkQTC(tempQTC2)\n",
    "        \n",
    "        ggg = tempQTC.shape[0]\n",
    "\n",
    "        handDataStruct.append([currComb[0], currComb[1], infoK[i][1], infoK[i][2], tempQTC.shape[0], tempQTC])\n",
    "        \n",
    "        if(verbose):\n",
    "            print '[%s]' % ', '.join(map(str, handDataStruct[-1][:-1]))\n",
    "            print str((ggg-gg)).ljust(3) + ' added in check QTC'\n",
    "            print str((gg-g)).ljust(3) + ' added in unique QTC'\n",
    "            print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here model trains recognition of object location wrt each other\n",
    "#feature vector => handDataStruct[5][:,5:8](vector from hand to object) and humanlabel handDataStruct[5][:,9]\n",
    "for a in range(len(handDataStruct)):\n",
    "    if(a == 0):\n",
    "        allPoseY = handDataStruct[a][5][:,5:8]\n",
    "#         allPoseY = handDataStruct[a][5][:,11:]\n",
    "        allPoseL = handDataStruct[a][5][:,9,None]\n",
    "    else:\n",
    "        allPoseY = np.vstack((allPoseY, handDataStruct[a][5][:,5:8]))\n",
    "#         allPoseY = np.vstack((allPoseY, handDataStruct[a][5][:,11:]))\n",
    "        allPoseL = np.vstack((allPoseL, handDataStruct[a][5][:,9,None]))\n",
    "    \n",
    "        \n",
    "print allPoseY.shape\n",
    "print allPoseL.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 0\n",
    "ratio = 70\n",
    "numItems = 300\n",
    "\n",
    "for k in range(len(humanStaticLabels)):\n",
    "    this_label = [i for i in range(allPoseL.shape[0]) if allPoseL[i] == k]\n",
    "    this_Y = allPoseY[this_label]\n",
    "    this_L = allPoseL[this_label]\n",
    "    if(len(this_L)< numItems-1):\n",
    "        Idx =range(len(this_L))\n",
    "    else:\n",
    "        Idx = [ i for i in sorted(random.sample(xrange(len(this_L)),numItems)) ]\n",
    "        \n",
    "    if(k == 0):\n",
    "        staticPoseY = np.asarray([this_Y[i] for i in Idx])\n",
    "        staticPoseL = np.asarray([this_L[i] for i in Idx])\n",
    "    else:\n",
    "        staticPoseY = np.vstack((staticPoseY, np.asarray([this_Y[i] for i in Idx])))\n",
    "        staticPoseL = np.vstack((staticPoseL, np.asarray([this_L[i] for i in Idx])))\n",
    "        \n",
    "print len(this_label)\n",
    "print len(this_Y)\n",
    "j = np.asarray(this_label)\n",
    "print j.shape\n",
    "print this_Y.shape\n",
    "print this_L.shape\n",
    "print staticPoseY.shape\n",
    "print staticPoseL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "staticPoseModel = staticPose.staticPose()\n",
    "staticPoseModel.readData(0,0,staticPoseY,staticPoseL, humanStaticLabels)\n",
    "\n",
    "staticPoseModel.Quser = 2\n",
    "Ntr = int(len(staticPoseModel.L)*ratio/100)\n",
    "model_type = 'mrd'\n",
    "model_num_inducing = 10\n",
    "model_num_iterations = 10 #100\n",
    "model_init_iterations = 10 #300\n",
    "save_model=True\n",
    "economy_save = True\n",
    "visualise_output=True\n",
    "experiment_number = 1\n",
    "fname = '/home/daniel/SAM_Data_Models/Models/staticPose_exp' + str(experiment_number)\n",
    "\n",
    "[Yall,Lall,YtestAll,LtestAll] = staticPoseModel.prepareData (model_type, Ntr,randSeed=experiment_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "staticPoseModel.training(model_num_inducing, model_num_iterations, model_init_iterations, fname, save_model, economy_save, keepIfPresent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # get the 2 most significant dims to plot on... if Q=2 it doesnt make a difference\n",
    "# dims = SAMCore.most_significant_input_dimensions(staticPoseModel.SAMObject.model,None)\n",
    "# N=6\n",
    "# # !!!! Assume that labels are in 2nd modality... changed accordingly if not!!!\n",
    "# labels_training = staticPoseModel.L\n",
    "# import colorsys\n",
    "# HSV_tuples = [(x*1.0/N, 0.5, 0.5) for x in range(len(labels_training))]\n",
    "# RGB_tuples = map(lambda x: colorsys.hsv_to_rgb(*x), HSV_tuples)\n",
    "# plt.figure()\n",
    "# for i in range(staticPoseModel.SAMObject.model.Y.shape[0]):\n",
    "#     c = RGB_tuples[int(labels_training[i,:])]\n",
    "#     plt.plot(staticPoseModel.SAMObject.model.X.mean.values[i,dims[0]],staticPoseModel.SAMObject.model.X.mean.values[i,dims[1]],'o',color=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# # Plot the latent embedding for a test data point\n",
    "# tt=0\n",
    "# ystar = staticPoseModel.Ytest[tt,:][None,:]\n",
    "# # DONT FORGET TO NORMALIZE TEST DATA SIMILARLY AS TRAINING DATA\n",
    "# ystar = (ystar - staticPoseModel.Ymean)/staticPoseModel.Ystd\n",
    "# xstar = staticPoseModel.SAMObject.pattern_completion(ystar,view=0)[0]    \n",
    "# plt.plot(xstar[:,dims[0]],xstar[:,dims[1]],'k<',markersize=16)\n",
    "\n",
    "# # Infer label\n",
    "# label_pred = staticPoseModel.SAMObject.pattern_completion_inference(ystar,target_modality=1)\n",
    "# print '# I predict label ' + str(staticPoseModel.Ltest[tt,:]) + ' to be label ' + str(label_pred)\u0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if visualise_output: \n",
    "ax = staticPoseModel.SAMObject.visualise()\n",
    "visualiseInfo=dict()\n",
    "visualiseInfo['ax']=ax\n",
    "# else:\n",
    "#     visualiseInfo=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# curTestData = Yall[][None,:].tolist()\n",
    "def formatDataFunc(Ydata):\n",
    "        yDataList = []\n",
    "        for j in range(Ydata.shape[0]):\n",
    "            yDataList.append(Ydata[j][None,:])\n",
    "        return yDataList\n",
    "\n",
    "def testFunc(data, lab):\n",
    "    d = staticPoseModel.testing(data, False)\n",
    "    if(lab == d[0]):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    print 'Actual  ' + str(lab).ljust(11) + '  Model:  ' + str(d[0]).ljust(11) + '  with ' + str(d[1])[:6] + ' confidence: ' + str(result) + '\\n'\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, targetNames, title='Confusion matrix', cmap=plt.cm.inferno):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(targetNames))\n",
    "    plt.xticks(tick_marks, targetNames, rotation=45)\n",
    "    plt.yticks(tick_marks, targetNames)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def wait_watching_stdout(ar, dt=1, truncate=1000):\n",
    "    while not ar.ready():\n",
    "        stdouts = ar.stdout\n",
    "        if any(stdouts):\n",
    "            clear_output()\n",
    "            print '-' * 30\n",
    "            print \"%.3fs elapsed\" % ar.elapsed\n",
    "            print \"\"\n",
    "            for stdout in ar.stdout:\n",
    "                if stdout:\n",
    "                    print \"\\n%s\" % (stdout[-truncate:])\n",
    "            sys.stdout.flush()\n",
    "        time.sleep(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = ipp.Client()\n",
    "dview = c[:]\n",
    "\n",
    "with dview.sync_imports():\n",
    "    from SAM.SAM_Core import staticPose\n",
    "\n",
    "dview.push({'staticPoseModel':staticPoseModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss = []\n",
    "sstest = []\n",
    "print\n",
    "off1 = 11\n",
    "off2 = 8\n",
    "\n",
    "# allCount = Yall.shape[0]\n",
    "# factor = 40\n",
    "# numItems = int(allCount/factor)\n",
    "cmSize = len(staticPoseModel.textLabels)\n",
    "confMatrix = np.zeros((cmSize, cmSize))\n",
    "numItems = Yall.shape[0]\n",
    "\n",
    "off3 = len(str(numItems))\n",
    "\n",
    "print 'estimated time: ' + str(numItems/60) + 'mins for ' + str(numItems) + ' items'\n",
    "#format training data\n",
    "\n",
    "yTrainingData = formatDataFunc(Yall)\n",
    "YsampleIdx = [ i for i in sorted(random.sample(xrange(len(yTrainingData)),numItems)) ]\n",
    "\n",
    "Ysample = [yTrainingData[i] for i in YsampleIdx]\n",
    "Lsample = [staticPoseModel.textLabels[int(Lall[i])] for i in YsampleIdx]\n",
    "\n",
    "%time syn = dview.map_async(testFunc, Ysample, Lsample)\n",
    "wait_watching_stdout(syn, dt=1, truncate=1000)\n",
    "ret = syn.get()\n",
    "# clear_output()\n",
    "for i in range(len(ret)):\n",
    "\n",
    "    currLabel = Lsample[i]\n",
    "\n",
    "    if(currLabel == ret[i][0]):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    print str(i).rjust(off3) + '/' + str(numItems) + ' Truth: ' + currLabel.ljust(off1) + ' Model: ' + ret[i][0].ljust(off1) + ' with ' + str(1-ret[i][1])[:6].ljust(off2) + ' confidence: ' + str(result)\n",
    "    confMatrix[staticPoseModel.textLabels.index(currLabel),staticPoseModel.textLabels.index(ret[i][0])] += 1\n",
    "    ss.append(ret[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confMatLabels = copy.deepcopy(staticPoseModel.textLabels)\n",
    "confMatLabels.sort()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "h = confusion_matrix(Lsample, ss)\n",
    "print h\n",
    "plot_confusion_matrix(h, confMatLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "percCorect = 100*np.diag(h.astype(np.float)).sum()/numItems\n",
    "\n",
    "normConf = h / h.astype(np.float).sum(axis=0)\n",
    "normConf = np.nan_to_num(normConf)\n",
    "print\n",
    "print 'Nomalised Confusion Matrix = '\n",
    "print normConf\n",
    "print \n",
    "\n",
    "print str(percCorect)[:5].ljust(7) + \" % correct for training data\"\n",
    "\n",
    "for i in range(cmSize):\n",
    "    for j in range(cmSize):\n",
    "        print str(normConf[i,j]*100)[:5].ljust(7) + '% of ' + str(staticPoseModel.textLabels[i]) + ' classified as ' + str(staticPoseModel.textLabels[j])\n",
    "    print\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# allCount = Yall.shape[0]\n",
    "# factor = 40\n",
    "# numItems = int(allCount/factor)\n",
    "cmSize = len(staticPoseModel.textLabels)\n",
    "confMatrixTest = np.zeros((cmSize, cmSize))\n",
    "numItems = YtestAll.shape[0]\n",
    "\n",
    "off3 = len(str(numItems))\n",
    "\n",
    "print 'estimated time: ' + str(numItems/60) + 'mins for ' + str(numItems) + ' items'\n",
    "#format training data\n",
    "\n",
    "yTrainingData = formatDataFunc(YtestAll)\n",
    "YsampleIdx = [ i for i in sorted(random.sample(xrange(len(yTrainingData)),numItems)) ]\n",
    "\n",
    "Ysample = [yTrainingData[i] for i in YsampleIdx]\n",
    "Lsample = [staticPoseModel.textLabels[int(LtestAll[i])] for i in YsampleIdx]\n",
    "\n",
    "%time syn = dview.map_async(testFunc, Ysample, Lsample)\n",
    "wait_watching_stdout(syn, dt=1, truncate=1000)\n",
    "ret = syn.get()\n",
    "clear_output()\n",
    "for i in range(len(ret)):\n",
    "\n",
    "    currLabel = Lsample[i]\n",
    "\n",
    "    if(currLabel == ret[i][0]):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    print str(i).rjust(off3) + '/' + str(numItems) + ' Truth: ' + currLabel.ljust(off1) + ' Model: ' + ret[i][0].ljust(off1) + ' with ' + str(1-ret[i][1])[:6].ljust(off2) + ' confidence: ' + str(result)\n",
    "    sstest.append(ret[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confMatrixTest = confusion_matrix(sstest, Lsample)\n",
    "print confMatrixTest\n",
    "plot_confusion_matrix(confMatrixTest, confMatLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "percCorect = 100*np.diag(confMatrixTest.astype(np.float)).sum()/numItems\n",
    "\n",
    "normConf = confMatrixTest / confMatrixTest.astype(np.float).sum(axis=0)\n",
    "normConf = np.nan_to_num(normConf)\n",
    "print\n",
    "print 'Nomalised Confusion Matrix = '\n",
    "print normConf\n",
    "print \n",
    "\n",
    "print str(percCorect)[:5].ljust(7) + \" % correct for testing data\"\n",
    "\n",
    "for i in range(cmSize):\n",
    "    for j in range(cmSize):\n",
    "        print str(normConf[i,j]*100)[:5].ljust(7)  + '% of ' + str(staticPoseModel.textLabels[i]) + ' classified as ' + str(staticPoseModel.textLabels[j])\n",
    "    print\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
